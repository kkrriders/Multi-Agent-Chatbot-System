{
  "name": "multi-agent-chat",
  "version": "1.0.0",
  "description": "Multi-Agent Chatbot System using Ollama LLMs",
  "main": "index.js",
  "scripts": {
    "start-manager": "node manager/index.js",
    "start-agent-mistral": "node agent-mistral/index.js",
    "start-agent-llama3": "node agent-llama3/index.js",
    "start-agent-phi3": "node agent-phi3/index.js",
    "start-agent-qwen": "node agent-qwen/index.js",
    "start-agent-llama33": "node agent-llama33/index.js",
    "start": "concurrently --names \"MANAGER,MISTRAL,LLAMA3,PHI3,QWEN,LLAMA33\" -c \"bgBlue.bold,bgGreen.bold,bgYellow.bold,bgMagenta.bold,bgCyan.bold,bgRed.bold\" \"npm run start-manager\" \"npm run start-agent-mistral\" \"npm run start-agent-llama3\" \"npm run start-agent-phi3\" \"npm run start-agent-qwen\" \"npm run start-agent-llama33\"",
    "start-all": "concurrently --names \"MANAGER,MISTRAL,LLAMA3,PHI3,QWEN,LLAMA33\" -c \"bgBlue.bold,bgGreen.bold,bgYellow.bold,bgMagenta.bold,bgCyan.bold,bgRed.bold\" \"npm run start-manager\" \"npm run start-agent-mistral\" \"npm run start-agent-llama3\" \"npm run start-agent-phi3\" \"npm run start-agent-qwen\" \"npm run start-agent-llama33\"",
    "download-models": "node download-models.js",
    "test": "node test-client.js",
    "test-scenario": "node test-chat-scenario.js",
    "run-demo": "node run-demo.js",
    "structured-record": "node structured-record.js",
    "custom-project": "node custom-project.js",
    "separate-records": "node separate-records.js",
    "stop": "node stop-services.js",
    "setup": "npm install && npm run download-models",
    "view-logs": "node view-conversations.js"
  },
  "keywords": [
    "chatbot",
    "llm",
    "ollama",
    "multi-agent"
  ],
  "author": "",
  "license": "MIT",
  "dependencies": {
    "axios": "^1.6.2",
    "cors": "^2.8.5",
    "dotenv": "^16.3.1",
    "express": "^4.18.2",
    "html-pdf": "^3.0.1",
    "morgan": "^1.10.0",
    "multer": "^2.0.0",
    "pdf-parse": "^1.1.1",
    "uuid": "^11.1.0",
    "winston": "^3.11.0"
  },
  "devDependencies": {
    "chalk": "^4.1.2",
    "concurrently": "^8.2.2"
  }
}
